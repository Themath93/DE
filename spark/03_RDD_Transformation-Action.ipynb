{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation - Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD Transformation\n",
    "\n",
    "-  데이터를 가공하기 위한 논리적 실행계획\n",
    "-  기존의 RDD에 연산이 반영된 새로운 RDD를 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation 메서드\n",
    "\n",
    "1. filter()\n",
    "2. map()\n",
    "3. flatMap()\n",
    "4. distinct()\n",
    "5. zip()\n",
    "6. join()\n",
    "6. reduceByKey()\n",
    "7. mapValues()\n",
    "8. sortBy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['홍길동 스파크 80']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rdd = sc.textFile(\"/rdd/score.txt\")\n",
    "#filter()\n",
    "# 조건에 맞는 데이터만\n",
    "score_rdd.filter(lambda e :  '스파크' in e ).filter(lambda e : '홍길' in e).collect()\n",
    "# type(score_rdd.filter(lambda e :  '스파크' in e ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 6, 10, 14, 18]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map()\n",
    "data = [1, 3, 5, 7, 9]\n",
    "map_rdd = sc.parallelize(data)\n",
    "map_rdd.map(lambda e: e * 2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - flatMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 100, 4, 5, 6, 100, 7, 8, 9, 100]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatMap()\n",
    "# 각각의 요소에 함수를 적용한 다음 평면화 시켜주는 함수\n",
    "nlist = [[1, 2, 3], \n",
    "         [4, 5, 6], \n",
    "         [7, 8, 9]]\n",
    "\n",
    "flat_rdd = sc.parallelize(nlist)\n",
    "\n",
    "def append_data(e):\n",
    "    e.append(100)\n",
    "    return e\n",
    "\n",
    "res = flat_rdd.flatMap(lambda e : append_data(e)).collect()\n",
    "len(res)\n",
    "# [[1, 2, 3, 100], [4, 5, 6, 100], [7, 8, 9, 100]]\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [[1, 2, 3,], 4, 5]\n",
    "# sc.parallelize(tmp).flatMap(lambda e: e).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하',\n",
       " '명',\n",
       " '도',\n",
       " ' ',\n",
       " '스',\n",
       " '파',\n",
       " '크',\n",
       " ' ',\n",
       " '5',\n",
       " '0',\n",
       " '점',\n",
       " '홍',\n",
       " '길',\n",
       " '동',\n",
       " ' ',\n",
       " '스',\n",
       " '파',\n",
       " '크',\n",
       " ' ',\n",
       " '8',\n",
       " '0',\n",
       " '점',\n",
       " '임',\n",
       " '꺽',\n",
       " '정',\n",
       " ' ',\n",
       " '스',\n",
       " '파',\n",
       " '크',\n",
       " ' ',\n",
       " '6',\n",
       " '0',\n",
       " '점',\n",
       " '임',\n",
       " '요',\n",
       " '환',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '점',\n",
       " '홍',\n",
       " '진',\n",
       " '호',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '2',\n",
       " '2',\n",
       " '점',\n",
       " '홍',\n",
       " '진',\n",
       " '호',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '2',\n",
       " '2',\n",
       " '점',\n",
       " '이',\n",
       " '윤',\n",
       " '열',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '9',\n",
       " '0',\n",
       " '점']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = score_rdd.flatMap(lambda e : e + '점').collect()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 : filter, map, flatMap \n",
    "\n",
    "nlist안의 요소들중 홀수인 요소만 추출하여 100을 곱하여 list로 반환하시오  \n",
    "\n",
    " - nlist = [[[1, 2], [3, 4, 5]],[[6, 7], [8, 9, 10, 11]],[[12,13,14,15], [16, 17]]]\n",
    "\n",
    " - 결과 : [100, 300, 500, 700, 900, 1100, 1300, 1500, 1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 300, 500, 700, 900, 1100, 1300, 1500, 1700]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlist = [[[1, 2], [3, 4, 5]],[[6, 7], [8, 9, 10, 11]],[[12,13,14,15], [16, 17]]]\n",
    "flat_rdd2 = sc.parallelize(nlist)\n",
    "flat_rdd2.flatMap(lambda e: e) \\\n",
    "          .flatMap(lambda e: e) \\\n",
    "          .filter(lambda e: e % 2 == 1) \\\n",
    "          .map(lambda e: e * 100) \\\n",
    "          .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:=============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hello', '안녕', '반가워']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlist = [1, 2, 3, 1, 2, 3, 1, 2, 3 , 4, 5]\n",
    "distinct_rdd = sc.parallelize(nlist)\n",
    "distinct_rdd.distinct().collect()\n",
    "\n",
    "slist = ['안녕','반가워','hello','hello']\n",
    "distinct_rdd2 = sc.parallelize(slist)\n",
    "distinct_rdd2.distinct().collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('양식', '파스타'), ('양식', '스테이크'), ('한식', '불고기'), ('한식', '비빔밥'), ('한식', '김치')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip() : 두 rdd를 결합해 key-value 형태의 rdd(Pair RDD)로 생성\n",
    "foods = ['파스타','스테이크', '불고기', '비빔밥', '김치']\n",
    "category = ['양식', '양식', '한식', '한식', '한식']\n",
    "\n",
    "foods_rdd = sc.parallelize(foods)\n",
    "category_rdd = sc.parallelize(category)\n",
    "zip_rdd = category_rdd.zip(foods_rdd)\n",
    "zip_rdd\n",
    "zip_rdd.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip 결과\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('양식', '파스타'), ('양식', '스테이크'), ('한식', '불고기'), ('한식', '비빔밥'), ('한식', '김치')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuple의 list로 RDD를 생성하면 Pair RDD 생성된다.\n",
    "tmp = list(map(lambda a, b : (a, b) , category,  foods))\n",
    "tmp_rdd = sc.parallelize(tmp)\n",
    "tmp_rdd.collect()\n",
    "\n",
    "tmp = list(zip(category,  foods))\n",
    "tmp_rdd = sc.parallelize(tmp)\n",
    "print('zip 결과')\n",
    "tmp_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - reduceByKey(), mapValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('양식', ['파스타', '스테이크']), ('한식', ['불고기', '비빔밥', '김치'])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduceByKey, 키값을 기준으로 value값들을 연산\n",
    "# mapValues, Pair RDD의 value들에 대해 map연산을 수행\n",
    "res = zip_rdd.reduceByKey(lambda a, b : a + ',' + b) \\\n",
    "         .mapValues(lambda e : e.split(',')) \n",
    "res.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - sortBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('양식', ['파스타', '스테이크']), ('한식', ['불고기', '비빔밥', '김치'])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키값으로 내림차순\n",
    "res.sortBy(lambda e : e[0], ascending=False).collect()\n",
    "\n",
    "# value값으로 오름차순\n",
    "# 메뉴 가짓 수로 오름차순\n",
    "print('===================================')\n",
    "res.sortBy(lambda e : len(e[1]), ascending=False).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 : distinct, zip, reduceByKey, sortBy \n",
    " - hdfs의 /score.txt 파일을 읽어와 RDD로 생성하시오\n",
    " - 각 과목별 명단을 추출하시오\n",
    " - 각 과목별 평균점수를 추출하시오\n",
    " - 이때 중복으로 들어간 홍진호의 데이터는 한번만 적용되도록 합니다.  \n",
    " \n",
    " \n",
    " \n",
    " - 결과 :  \n",
    " [('스파크', {'명단': ['하명도', '홍길동', '임꺽정']}), ('텐서플로우', {'명단': ['임요환', '홍진호', '이윤열']})]       \n",
    "  \n",
    " [('스파크', {'평균점수': 63.333333333333336}), ('텐서플로우', {'평균점수': 70.66666666666667})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['이윤열', '텐서플로우', '90'],\n",
       " ['하명도', '스파크', '50'],\n",
       " ['홍길동', '스파크', '80'],\n",
       " ['임꺽정', '스파크', '60'],\n",
       " ['임요환', '텐서플로우', '100'],\n",
       " ['홍진호', '텐서플로우', '22']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('스파크', {'명단': ['임꺽정', '하명도', '홍길동']}),\n",
       " ('텐서플로우', {'명단': ['이윤열', '홍진호', '임요환']})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('스파크', {'평균점수': 63.333333333333336}), ('텐서플로우', {'평균점수': 70.66666666666667})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 지정한 DataSource에서 데이터를 읽어와 RDD를 생성\n",
    "score_rdd = sc.textFile(\"/rdd/score.txt\")\n",
    "base = score_rdd.distinct() \\\n",
    "                    .map(lambda e : e.split(' '))\n",
    "\n",
    "# base.collect()\n",
    "students = base.map(lambda e : (e[1], [e[0]])) \\\n",
    "                    .reduceByKey(lambda a, b : a + b) \\\n",
    "                    .mapValues(lambda e : {'명단': e})\n",
    "students.collect()\n",
    "\n",
    "score_avg = base.map(lambda e: (e[1], [int(e[2])])) \\\n",
    "                    .reduceByKey(lambda a, b : a+b) \\\n",
    "                    .mapValues(lambda e : {'평균점수':sum(e)/len(e)})\n",
    "\n",
    "score_avg.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스파크', ({'명단': ['하명도', '홍길동', '임꺽정']}, {'평균점수': 63.333333333333336})),\n",
       " ('텐서플로우', ({'명단': ['홍진호', '임요환', '이윤열']}, {'평균점수': 70.66666666666667}))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('스파크', {'명단': ['하명도', '홍길동', '임꺽정'], '평균점수': 63.333333333333336}),\n",
       " ('텐서플로우', {'명단': ['홍진호', '임요환', '이윤열'], '평균점수': 70.66666666666667})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키를 기준으로 두 RDD를 결합\n",
    "res = students.join(score_avg)\n",
    "res.collect()\n",
    "\n",
    "#[('스파크', {'명단': ['임꺽정', '하명도', '홍길동'], '평균점수': 63.333333333333336}),\n",
    "# ('텐서플로우', {'명단': ['이윤열', '홍진호', '임요환'], '평균점수': 70.66666666666667})]\n",
    "res = students.join(score_avg) \\\n",
    "                .mapValues(lambda e : dict(e[0], 평균점수=e[1]['평균점수']))\n",
    "res.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스파크에서 연산은 단일 파티션에서 작동   \n",
    "\n",
    "\n",
    "- reduceByKey와 같이 특정 키에 매핑된 모든 값에 대한 연산을 수행하기 위해서는   \n",
    "  파티션에 흩어진 특정키에 해당하는 값을 하나의 파티션으로 모아 줄 필요가 있음  \n",
    "\n",
    "\n",
    "- 모든 키에 대한 모든 값을 찾기 위해 모든 파티션을 탐색하고, 해당하는 값들을 하나의 파티션으로 옮겨오는 과정을 셔플이라고 부른다.  \n",
    "\n",
    "\n",
    "- 디스크 IO 또는 네트워크 IO가 발생함으로 비용이 매우 비싼 작업  \n",
    "\n",
    "\n",
    "\n",
    "ex)   \n",
    "filter : 각 파티션에 있는 하나의 튜플에 대해 조건을 탐색하면 됨으로 셔플 발생 x  \n",
    "reduceByKey : 연산을 시작하기 위해서는 우선적으로 모든 파티션에 분산되어 있는 특정 키 값을 수집해야함으로 셔플 발생 \n",
    "- 셔플이 발생하는 함수들 :\n",
    " - subtractByKey\n",
    " - groupBy\n",
    " - foldByKey\n",
    " - reduceByKey\n",
    " - aggregateByKey\n",
    " - transformations of a join of any type\n",
    " - distinct\n",
    " - cogroup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shuffle](./img/shuffle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD Action\n",
    "\n",
    "- transformation 연산을 통해 생성한 논리적 실행계획을 최적화 하여 연산을 수행. 빠른 연산이 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Method\n",
    "\n",
    "1. collect()\n",
    "2. take()\n",
    "3. takeOrdered()\n",
    "4. top()\n",
    "5. countByValue()\n",
    "6. foreach()\n",
    "7. reduce()\n",
    "8. saveAsTextFile()\n",
    "9. max()\n",
    "10. min()\n",
    "11. mean()\n",
    "12. variance()\n",
    "13. stdev()\n",
    "14. stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하명도 스파크 50',\n",
       " '홍길동 스파크 80',\n",
       " '임꺽정 스파크 60',\n",
       " '임요환 텐서플로우 100',\n",
       " '홍진호 텐서플로우 22',\n",
       " '홍진호 텐서플로우 22',\n",
       " '이윤열 텐서플로우 90']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rdd = sc.textFile('/rdd/score.txt')\n",
    "score_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the first num elements of the RDD.\n",
    "data = [1, 2, 3, 4, 5]\n",
    "take_rdd = sc.parallelize(data)\n",
    "take_rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - takeOrdered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 1, 20, 32]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[400, 100, 51, 32]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1, 20, 32, 400, 51, 100, 0.1]\n",
    "to_rdd = sc.parallelize(data)\n",
    "to_rdd.takeOrdered(4)\n",
    "to_rdd.takeOrdered(4, lambda e : -e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51, 400, 32]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1, 20, 32, 400, 51, 100, 0.1]\n",
    "to_rdd = sc.parallelize(data)\n",
    "to_rdd.top(3, key=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 3, 'b': 4, 'c': 2, 'de': 2})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaa\n"
     ]
    }
   ],
   "source": [
    "chars_rdd = sc.parallelize(['a', 'a', 'a', 'b', 'b', 'b', 'b', 'c', 'c', 'de', 'de',])\n",
    "chars_rdd.countByValue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "nums.reduce(lambda a, b : a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - foreach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): \n",
    "    print(x)\n",
    "sc.parallelize([1, 2, 3, 4, 5]).foreach(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - saveAsTextFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 지정한 DataSource에서 데이터를 읽어와 RDD를 생성\n",
    "score_rdd = sc.textFile(\"/rdd/score.txt\")\n",
    "base = score_rdd.distinct() \\\n",
    "                    .map(lambda e : e.split(' '))\n",
    "\n",
    "students = base.map(lambda e : (e[1], [e[0]])) \\\n",
    "                    .reduceByKey(lambda a, b : a + b) \\\n",
    "                    .mapValues(lambda e : {'명단': e})\n",
    "\n",
    "score_avg = base.map(lambda e: (e[1], [int(e[2])])) \\\n",
    "                    .reduceByKey(lambda a, b : a+b) \\\n",
    "                    .mapValues(lambda e : {'평균점수':sum(e)/len(e)})\n",
    "res = students.join(score_avg)\n",
    "res = students.join(score_avg) \\\n",
    "                .mapValues(lambda e : dict(e[0], 평균점수=e[1]['평균점수']))\n",
    "res.saveAsTextFile('/rdd/score_transform.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"('스파크', {'명단': ['임꺽정', '하명도', '홍길동'], '평균점수': 63.333333333333336})\",\n",
       " \"('텐서플로우', {'명단': ['이윤열', '임요환', '홍진호'], '평균점수': 70.66666666666667})\"]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = sc.textFile('/rdd/score_transform.txt')\n",
    "test.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - max, min, mean, variance, stdev, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(count: 7, mean: 4.0, stdev: 2.0, max: 7, min: 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = sc.parallelize([1, 4, 2, 3, 7, 6, 5])\n",
    "nums.max()\n",
    "nums.min()\n",
    "nums.mean()\n",
    "nums.variance()\n",
    "nums.stdev()\n",
    "nums.stats()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
